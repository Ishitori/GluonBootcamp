{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "<keras.callbacks.ModelCheckpoint object at 0x7f9cf603bef0>\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      " 2176/60000 [>.............................] - ETA: 3s - loss: 1.7380 - acc: 0.4453"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:89: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  train_symbol = func(*args, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:92: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  test_symbol = func(*args, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/losses.py:128: UserWarning: MXNet Backend: If you are using a custom loss function and use slice operator in custom loss function, please set the **_keras_shape** attribute of the loss tensor explicitly.\n",
      "\n",
      "Without this workaround, you may encounter shape mismatch errors in the broadcast operations.\n",
      "\n",
      "For more details - https://github.com/awslabs/keras-apache-mxnet/issues/120\n",
      "\n",
      "\n",
      "  warnings.warn('MXNet Backend: If you are using a custom loss function and use slice operator in custom '\n",
      "/home/ubuntu/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.0078125). Is this intended?\n",
      "  force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3522 - acc: 0.8925 - val_loss: 0.0800 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08000, saving model to /tmp/weights.hdf5\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1177 - acc: 0.9653 - val_loss: 0.0520 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08000 to 0.05203, saving model to /tmp/weights.hdf5\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0874 - acc: 0.9741 - val_loss: 0.0432 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05203 to 0.04319, saving model to /tmp/weights.hdf5\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0737 - acc: 0.9780 - val_loss: 0.0367 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04319 to 0.03674, saving model to /tmp/weights.hdf5\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0641 - acc: 0.9808 - val_loss: 0.0350 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03674 to 0.03495, saving model to /tmp/weights.hdf5\n",
      "Test loss: 0.0349535019183\n",
      "Test accuracy: 0.988\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  mnist_cnn-symbol.json\n",
      "MXNet params file -  mnist_cnn-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_9_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_9_input1,(128, 28, 28, 1),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n"
     ]
    }
   ],
   "source": [
    "# Reference - https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "# Step 1: Train a CNN model for MNIST dataset.\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Embedding\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Import the save_mxnet_model API\n",
    "from keras.models import save_mxnet_model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "print(checkpointer)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[checkpointer])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Step 2: Save the model in MXNet model format.\n",
    "# data_names and data_shapes are values of the parameters to be used when loading the Model in MXNet.\n",
    "data_names, data_shapes = save_mxnet_model(model=model, prefix='mnist_cnn', epoch=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mxnet_p36)",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
